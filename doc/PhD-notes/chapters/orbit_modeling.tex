\chapter{Satellite Orbit modeling}
\label{ch:satellite-orbit-modeling}

\section{Linearization of the Orbit Determination Process}
In the general orbit determination problem, both the dynamics and the measurements 
involve significant nonlinear relationships. For the general case, the governing 
relations involve the nonlinear expression:
%\begin{equation}
\begin{align}
  \label{eq:tapley421}
  \dot{\vec{x}} = F( \vec{x}, t )                 , & \quad \vec{x}(t_k ) \equiv \vec{x}_k \\
  \label{eq:tapley422}
  \vec{y}_i = G( \vec{x}_i , t_i ) + {\epsilon}_i , & \quad  i=1,2,\ldots ,l
\end{align}
%\end{equation}

where \(\vec{x}_k\) is the unknown \(n\)-dimensional state vector at time \(t_k\) and 
\(\vec{y}_i\) for \(i=1,2,\ldots ,l\) is a \(p\)-dimensional set of observations. The 
\emph{best estimate} of the state vector \(\vec{x}_k\) will be denoted as \(\hat{\vec{x}}_k\). 
In general, \(p<n\) and \( m = p \times l \gg n \). The formulation described by the 
system \ref{eq:tapley421} and \ref{eq:tapley422}, is characterized by: (\cite{tapley})
\begin{enumerate}
  \item the inability to observe the state (\(\vec{x}_k\)) directly,
  \item nonlinear relations between the observations and the state, 
  \item fewer observations at any time epoch \(i\) than there are state vector 
  components (\(p<n\)), and 
  \item errors in the observations represented by \({\epsilon}_i\)
\end{enumerate}

If a reasonable reference trajectory \(\vec{x}*\) is available and if 
\(\vec{x}\), the true trajectory, and the reference trajectory remain sufficiently 
close throughout the time interval of interest, then the trajectory for the actual 
motion can be expanded in a Taylorâ€™s series about the reference trajectory at 
each point in time. Eliminating higher order terms, the deviation in the state
from the reference trajectory can be described by a set of linear differential 
equations. Corresponding linear relations can be derived between the observation 
and the state deviations, thus transforming the nonlinear orbit determination problem 
to a linear one.

If \(\vec{\delta x}\) is the \( n \times 1 \) state deviation vector and 
\(\vec{\delta y}\) is the \(p \times 1\) observation deviation:
\begin{equation}
  \begin{aligned}
    \vec{\delta x} (t) &= \vec{x}(t) - \vec{x}^* (t) \\
    \vec{\delta y} (t) &= \vec{y}(t) - \vec{y}^*(t)
  \end{aligned}
\end{equation}

hence

\begin{equation}
  \dot{\vec{\delta x}} (t) = \dot{\vec{x}} (t) - \dot{\vec{x}}^* (t)
\end{equation}

Expanding \ref{eq:tapley421} and \ref{eq:tapley422} in a Taylor series about the 
reference trajectory, leads to:
\begin{equation}
\label{eq:tapley425}
\begin{aligned}
  \dot{\vec{x}} (t) &= F (\vec{x}, t) \\
   & \approx F (\vec{x}^* , t) 
    + \left.\frac{\partial F(t)}{\partial \vec{x}(t)}\right|_{\vec{x}^*} \left( \vec{x}(t) - \vec{x}^* (t) \right)
    + O_F \left( \vec{x}(t) - \vec{x}^* (t) \right) \\
    \vec{y}_i &= G( \vec{x}_i , t_i ) + {\epsilon}_i = \\ & \approx G( \vec{x}^*_i , t_i )
    + \left.\frac{\partial G}{\partial \vec{x}}\right|_{\vec{x}^* , i} \left.\left( \vec{x}(t_i) - \vec{x}^* (t_i) \right)\right|_{i} 
    + O_G \left( \vec{x}(t_i) - \vec{x}^* (t_i) \right) + {\epsilon}_i \\
\end{aligned}
\end{equation}

where \(\left.\frac{\partial}{\partial \vec{x}}\right|_{\vec{x}^*}\) indicates that 
the partial derivative matrix is evaluated on the reference solution \(\vec{x}^* (t)\) 
which is obtained by integrating \ref{eq:tapley421} with the initial conditions 
\(\vec{x}^* (t_0)\). \(O_F\) and \(O_G\) indicate terms higher than the 1\textsuperscript{st} 
order which are ignored. Noting that \(\dot{\vec{x}}^* = F(\vec{x}^* ,t)\) and 
\(\vec{y}^*_i = G(\vec{x}^*_i , t_i )\), and letting
\begin{equation}
\begin{aligned}
\delta \vec{x}(t) & = \vec{x}(t) - \vec{x}^*(t)\\
\delta \vec{x}_i  & = \vec{x}(t_i) - \vec{x}^*(t_i)\\
\delta \vec{y}_i  & = \vec{y}_i - G(\vec{x}^*_i , t_i )
\end{aligned}
\end{equation}

\ref{eq:tapley421} can be written as:
\begin{align}
  \label{eq:tapley426a}
  \delta \dot{\vec{x}}(t) &= A(t) \delta \vec{x}(t) \\
  \label{eq:tapley426b}
  \delta \vec{y}_i &= \tilde{H}_i \delta \vec{x}_i + {\epsilon}_i \quad (i=1,\ldots,l)
\end{align}

where
\begin{equation}
A(t) = \left.\frac{\partial F(t)}{\partial \vec{x} (t)}\right|_{\vec{x}^*} 
\quad
\tilde{H}_i = \left.\frac{\partial G}{\partial \vec{x}}\right|_{\vec{x}^* , i}
\end{equation}

\section{State Transition Matrix}
\ref{eq:tapley426a} represents a system of linear differential equations with time-dependent 
coefficients; the general solution to the system, can be expressed as:
\begin{equation}
\label{eq:tapley427}
  \bm{x}(t) = \Phi (t, t_k) \cdot \bm{x}_k \quad \text{with } \bm{x}_k = \bm{x}(t_k)
\end{equation}

The matrix \(\Phi (t_i, t_k) \) is called the \emph{state transition matrix} and has the 
following properties:
\begin{itemize}
  \item \(\Phi (t_k, t_k) = I \)
  \item \(\Phi (t_i, t_k) = \Phi (t_i, t_j) \Phi (t_j, t_k) \)
  \item \(\Phi (t_i, t_k) = {\Phi}^{-1} (t_j, t_k) \)
\end{itemize}

Noting that \(\bm{x}_k\) is constant,
\begin{equation}
  \label{eq:tapley429}
  \bm{\dot{x}}(t) = \dot{\Phi} (t, t_k) \cdot \bm{x}_k
\end{equation}

Using \ref{eq:tapley426a} and \ref{eq:tapley427},
\begin{equation}
  \label{eq:tapley4210}
  \begin{aligned}
  \dot{\Phi} (t, t_k) \bm{x}_k & = A(t) \cdot \bm{x} (t) \\
  & = A(t) \cdot \Phi (t, t_k) \bm{x}_k \\ 
  \implies & \dot{\Phi} (t, t_k) = A(t) \Phi (t, t_k)
  \end{aligned}
\end{equation}

\ref{eq:tapley4210} represents a linear differential equation. For any practical orbit 
determination application, the solution for \(\Phi (t, t_0)\)  will be obtained
via numerical integration, supplying a vector of derivative values for the differential 
equation of the nominal state vector and computed values for \(\dot{\Phi} (t, t_0)\).

\section{Observations}
Combining \ref{eq:tapley427} and \ref{eq:tapley426b}, we get:
\begin{equation}
  \label{eq:tapley4237}
  \begin{aligned}
    \bm{y}_0 &= \tilde{H}_0 \Phi (t_0, t_k) \bm{x}_k + {\epsilon}_0 \\
    \bm{y}_1 &= \tilde{H}_1 \Phi (t_1, t_k) \bm{x}_k + {\epsilon}_1 \\
    & \vdotswithin{=} \\
    \bm{y}_{l-1} &= \tilde{H}_{l-1} \Phi (t_{l-1}, t_k) \bm{x}_k + {\epsilon}_{l-1}
  \end{aligned}
\end{equation}

where the system contains \(m=p\times l\) observations and \(n\) unknown components 
in the state vector. For convinience, we define the following notation:
\begin{equation}
  \bm{y} \equiv \begin{bmatrix} y_0 \\ y_1 \\ \ldots \\ y_{l-1} \end{bmatrix},
  \quad
  H \equiv \begin{bmatrix} \tilde{H}_0 \Phi (t_0, t_k) \\ \tilde{H}_1 \Phi (t_1, t_k) \\ \ldots \\ \tilde{H}_{l-1} \Phi (t_{l-1}, t_k) \end{bmatrix},
  \quad
  \bm{\epsilon} \equiv \begin{bmatrix} {\epsilon}_0 \\ {\epsilon}_1 \\ \ldots \\ {\epsilon}_{l-1} \end{bmatrix}
\end{equation}

so that we can now write \ref{eq:tapley4237} as:
\begin{equation}
  \label{eq:tapley4239}
  \bm{y} = H \bm{x} + \bm{\epsilon} 
  \quad
  \bm{y} \in \mathbb{R} ^{m \times 1},
  \bm{x} \in \mathbb{R} ^{n \times 1},
  H \in \mathbb{R}^{m \times n},
\end{equation}

where \( m = p \times l \) is the total number of observations.

\section{Square Root Filtering}
Sequential estimation algorithms are subject to the filter divergence phenomenon, during 
which the estimate of the state can depart in an unbounded manner from the true value 
of the state. There are two fundamental reasons for filter divergence (\cite{tapley}):
\begin{itemize}
  \item due to inaccuracies in the mathematical model used to describe the dynamic 
  process or in the model used to relate the observations to the state, and
  \item the state error covariance matrix during measurement update can become nonpositive 
  definite (a situation that is a theoretical impossibility) due to floating point 
  arithmetic when computing the update of the state error covariance matrix at the 
  point where an observation is incorporated \footnote{When the eigenvalues have a wide spread, the error
introduced in the computational process can destroy the symmetry and positive
definite character of the covariance matrix and filte r divergence may occur, see \cite{tapley}.}.
\end{itemize}

The latter point is addressed in modifications of the computational algorithm called 
\emph{square root covariance filters}, in which the state error covariance matrix is 
replaced by its square root. The state error covariance matrix is obtained by
multiplying the square root matrix by its transpose and will always be symmetric
and positive semidefinite.

If we define
\begin{equation}
\label{eq:tapley571}
P = W W^T
\end{equation}

where \(W\) is the state error covariance matrix square root, and use \ref{eq:tapley571} to 
compute the \(P\) matrix, this can never be nonpositive definite even in the presence 
of round-off or truncation errors. Furthermore, since \(P\) is symmetric and positive 
definite, there will exist an orthogonal matrix \(M\) such that:
\begin{equation}
\label{eq:tapley572}
  P^* = M^T P M
\end{equation}

where \(P^*\) is a diagonal matrix whose elements are the eigenvalues of \(P\) and 
\(M\) is the corresponding matrix of eigenvectors. Define \(W^*\) as the matrix 
whose diagonal elements are equal to the square root of the diagonal elements of \(P^*\)
\begin{equation}
  W^*_{ii} = \sqrt P^*_{ii} \quad i=1,\ldots ,n
\end{equation}
where \(P^*_{ii} > 0\), then
\begin{equation}
 W^* W^{*T} = P^* = M^T P M = M^T W W^T M
\end{equation}

Thus, \(W^* = M^T W \) and since \(M\) is an orthogonal matrix, it follows that
\begin{equation}
  \label{eq:tapley574}
  W = M W^*
\end{equation}

The numerical conditioning of \(W\) is generally much better than that of \(P\) (\cite{tapley}).
